{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 2000\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df = train_df.drop('Id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['SalePrice']\n",
    "train_df = train_df.drop('SalePrice', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide varbles by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date variables\n",
    "date_vars = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'MoSold', 'YrSold']\n",
    "\n",
    "# list comprehension of continuous variables that are not dates\n",
    "cont_vars = [cont_var for cont_var in train_df.columns if\n",
    "        (train_df[cont_var].dtype == 'float64') | (train_df[cont_var].dtype == 'int64')\n",
    "        and not cont_var in date_vars]\n",
    "\n",
    "# change continus varibles to float\n",
    "train_df[cont_vars] = train_df[cont_vars].astype('float64')\n",
    "\n",
    "# create dataframe of date variables\n",
    "dates = train_df[date_vars].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict compehension of the frequncy of unique varibales\n",
    "cont_freq = {cont_var: train_df[cont_var].nunique() for cont_var in cont_vars}\n",
    "# frequency data frame\n",
    "cont_freq_df = pd.DataFrame.from_dict(cont_freq, orient='index').rename(columns={0: 'freq'})\n",
    "# continuous variables with few unique values\n",
    "low_vol_cont = ['LowQualFinSF', '3SsnPorch', 'PoolArea']\n",
    "# variabkes with Nan as the mode\n",
    "mode_na = ['Alley', 'PoolQC', 'Fence','MiscFeature', 'FireplaceQu']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame with numerical variables \n",
    "nums = train_df[list(cont_freq_df[cont_freq_df.freq >= 50].index)].astype(object)\n",
    "\n",
    "num_cats = train_df[list(cont_freq_df[cont_freq_df.freq < 50].index)].astype(object)\n",
    "\n",
    "# list of non categorical variables\n",
    "non_cat = list(nums.columns) + list(dates.columns) + list(num_cats.columns) + mode_na\n",
    "# data frame with only categorical\n",
    "cats =  train_df.drop(non_cat, axis = 1)\n",
    "\n",
    "# data frame with categoricals where the mode is nan\n",
    "cats_na = train_df[mode_na]\n",
    "\n",
    "# move continuous variables with low-frequency from num_cats to nums\n",
    "nums[low_vol_cont] = num_cats[low_vol_cont]\n",
    "num_cats = num_cats.drop(low_vol_cont, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill numarical missing with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = nums.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add dummies remove dominate and original categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummies_remove_modes(dummy_list, house_raw, house_df):\n",
    "\n",
    "    dummy_modes = list(house_raw[dummy_list].mode().iloc[0,:].items())\n",
    "\n",
    "    dummy_modes = [(col, (float(mode))) \n",
    "                   if type(mode) == int else (col, mode) for col, mode in dummy_modes]\n",
    "\n",
    "    drop_modes = list(map(lambda x: str(x[0]) + '_' + str(x[1]), dummy_modes))\n",
    "\n",
    "    dummy_cols = pd.get_dummies(\n",
    "        house_df[dummy_list].astype(object), dummy_na=True).drop(drop_modes, axis=1)\n",
    "\n",
    "    return pd.concat([\n",
    "       house_df.drop(dummy_list, axis=1),\n",
    "       dummy_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numarical Categorical to Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute numarical categoricals with mode\n",
    "num_cats = num_cats.fillna(num_cats.mode())\n",
    "\n",
    "# dummify categotical numericals\n",
    "num_cats = add_dummies_remove_modes(list(num_cats.columns), train_df, num_cats)\n",
    "\n",
    "# drop columns that are all 0\n",
    "num_cats = num_cats.drop(\n",
    "    num_cats.columns[num_cats.sum()==0], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical to Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cats dummies\n",
    "cats = add_dummies_remove_modes(list(cats.columns), train_df, cats)\n",
    "\n",
    "cats = cats.drop(cats.columns[cats.sum()==0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummify columns with NA as mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_na = pd.get_dummies(cats_na)\n",
    "\n",
    "cats_na = cats_na.drop(cats_na.columns[cats_na.sum()==0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change GarageYrBlt to binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates['GarageYrBlt'] = ~dates['GarageYrBlt'].isna()\n",
    "dates['GarageYrBlt'] = dates['GarageYrBlt'].apply(lambda x: sum([x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = pd.concat([dates, nums, num_cats, cats, cats_na], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 337)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BldgType_Duplex',\n",
       " 'BsmtCond_nan',\n",
       " 'BsmtFinType1_nan',\n",
       " 'Condition2_RRAe',\n",
       " 'Exterior2nd_CBlock',\n",
       " 'GarageCond_nan',\n",
       " 'GarageFinish_nan',\n",
       " 'GarageQual_nan',\n",
       " 'GarageType_nan',\n",
       " 'TotRmsAbvGrd_14.0'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_before_drop = set(df_train_final.columns)\n",
    "cols_after_drop = set(df_train_final.T.drop_duplicates(keep='first').T.columns)\n",
    "cols_before_drop - cols_after_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_after_drop - cols_before_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = df_train_final.T.drop_duplicates(keep='first').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 327)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Dummies on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_frame = pd.get_dummies(\n",
    "    pd.concat([num_cats, cats, cats_na], axis=1))\n",
    "\n",
    "test_dummies = test_df.reindex(columns = dummies_frame.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_dummies, test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = set(df_train_final.columns)\n",
    "test_cols = set(test_df.columns)\n",
    "\n",
    "test_drop =  list(test_cols - train_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Check on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_cols - test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 327)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.drop(test_drop, axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Cols not in Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = test_df.drop(test_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_na_cols = test_df.columns[test_df.isna().sum() > 0]\n",
    "test_df[test_na_cols] = test_df[test_na_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Sale Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final['SalePrice'] = train_raw['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final.to_pickle('train.pkl')\n",
    "test_df.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
